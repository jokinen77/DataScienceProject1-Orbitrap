{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project 1 -  Improve the mass accuracy of spectra measured by Orbitrap mass spectrometers (orbitrap)\n",
    "\n",
    "**Client:** Atmospheric Physical Chemistry group, INAR, University of Helsinki\n",
    "\n",
    "**Description:** Motivation: When using a mass spectrometer, the measured mass usually shifts from its true mass. Hence, a mass calibration is an important procedure before allocating chemical formulae to the measured masses. A good mass calibration may greatly reduce the efforts of further analysis and increase the reliability of the results. Goals: Improve the mass calibration procedure for Orbitrap raw data, and perhaps for data measured by other mass spectrometers, e.g, TOF-MS Main tasks: 1) Test several fitting function for mass correction, and recommend one or a few that works best. 2) Test the performance of different parameters for mass correction, e.g., number of mass of the species for calibration.\n",
    "\n",
    "**Data and tools:** Data: raw spectrum data measured by Orbitrap mass spectrometer. Tools: a) Orbitool, provided by the client. Orbitool will be used for reading the raw data and remove the noise, i.e., prepare the data for this analysis; b) Any programming language, which will be used to investigate this mass calibration problem.\n",
    "\n",
    "## Environment\n",
    "\n",
    "The environment should have the dependencies to run Orbitool and this notebook.\n",
    "\n",
    "```bash\n",
    "# Import environment\n",
    "conda env create -f environment.yml\n",
    "\n",
    "# Import kernel to jupyter\n",
    "ipython kernel install --user --name=orbitool\n",
    "\n",
    "# Export the environment to file\n",
    "conda env export --no-builds > environment.yml\n",
    "```\n",
    "\n",
    "## Notebook practices\n",
    "\n",
    "* Clean outputs before commiting!\n",
    "\n",
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.signal import find_peaks\n",
    "from detecta import detect_peaks\n",
    "from scipy.optimize import leastsq\n",
    "from pyteomics import mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "### Read the spectrum data\n",
    "\n",
    "* Put the directory of spectrum CSV files to ```spectrum_data_directory``` variable.\n",
    "    * If the begining of the CSV files contains some time information, then set ```contains_time_data``` variable to ```True```.\n",
    "* Put the path of the peak list file to ```peak_list_file``` variable.\n",
    "* If you just want to test the code, then you can speed up the code by setting the size of spectrum sample to ```random_sample_size``` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_data_directory = \"data/CI-orbi_20201117165601 folder (first smal deviation file)/1 min\"\n",
    "contains_time_data = False #Spectrum files contains time data in forst 3 rows?\n",
    "peak_list_file = \"peak list/peaklist_1e5_background.csv\"\n",
    "random_sample_size = 5 #Take sample spectrums to speed up things. If 'None' then uses all the spectrums\n",
    "\n",
    "spectrum_data_files = []\n",
    "time_data = []\n",
    "spectrums = []\n",
    "\n",
    "# Get data files\n",
    "for file in [f for f in listdir(spectrum_data_directory) if isfile(join(spectrum_data_directory, f))]:\n",
    "    path_to_file = join(spectrum_data_directory, file)\n",
    "    #print(path_to_file)\n",
    "    if file.endswith(\".csv\"):\n",
    "        spectrum_data_files.append(path_to_file)\n",
    "\n",
    "# Take sample spectrums to speed up things\n",
    "if random_sample_size:\n",
    "    spectrum_data_files = random.sample(spectrum_data_files, min(random_sample_size, len(spectrum_data_files)))\n",
    "\n",
    "# Read the spectrum files\n",
    "for file in spectrum_data_files:\n",
    "    if contains_time_data:\n",
    "        time_data.append(pd.read_csv(file)[:2])\n",
    "        spectrums.append(pd.read_csv(file, skiprows = 3).sort_values(by=['mz']))\n",
    "    else:\n",
    "        spectrums.append(pd.read_csv(file))\n",
    "\n",
    "peak_list = dict(pd.read_csv(peak_list_file).values)\n",
    "\n",
    "# Lookup\n",
    "spectrums[0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot  the spectrums\n",
    "\n",
    "* Plot all the spectrums with actual ions (from peak list file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# seaborn version should be at least 0.11!\n",
    "print(sns.__version__)\n",
    "\n",
    "# Concat files to same data frame with 'spectrum' separator column\n",
    "tmp = pd.concat(spectrums, keys=range(len(spectrum_data_files)), names=[\"spectrum\"])\n",
    "\n",
    "# Plot the spectrums\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.lineplot(data=tmp, ax=ax, x=\"mz\", y=\"intensity\", hue=\"spectrum\", palette=\"tab10\")\n",
    "ax.legend([],[], frameon=False)\n",
    "ax.ticklabel_format(useOffset=False)\n",
    "\n",
    "# Plot the actual masses. Line height is taken from max intensity with +-eps interval.\n",
    "eps = 0.0001\n",
    "for formula, mz in peak_list.items():\n",
    "    max_intensity = max([x for x in tmp.loc[(tmp[\"mz\"] > mz - eps) & (tmp[\"mz\"] < mz + eps)].intensity.values] + [0.0])\n",
    "    plt.plot((mz,mz), (0.0,max_intensity), linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect peaks\n",
    "\n",
    "* Detect peaks\n",
    "* Calculate/get some information about the peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_peak_indices(data):\n",
    "    '''\n",
    "    Logic is same as in Koli's implementation. Tested that produces same results with spectrums in\n",
    "    \"data/CI-orbi_20201117165601 folder (first smal deviation file)/1 min\" folder.\n",
    "    '''\n",
    "    peak_start_indices = [0] #Initialize with first start index\n",
    "    peak_end_indices = []\n",
    "    for i, row in data.iterrows():\n",
    "        if i == 0:\n",
    "            continue;\n",
    "        if data.iloc[i][\"intensity\"] == 0.0 and data.iloc[i - 1][\"intensity\"] == 0.0:\n",
    "            peak_start_indices.append(i)\n",
    "            peak_end_indices.append(i - 1)\n",
    "    peak_end_indices.append(len(data) - 1) #Finalize with last end index\n",
    "    return np.column_stack((peak_start_indices, peak_end_indices))\n",
    "\n",
    "peak_informations = []\n",
    "for spectrum in spectrums:\n",
    "    peak_information = []\n",
    "    for start, end in find_peak_indices(spectrum):\n",
    "        data = spectrum.iloc[start:(end+1)]\n",
    "        max_intensity = data[\"intensity\"].max()\n",
    "        width = data[\"mz\"].max() - data[\"mz\"].min()\n",
    "        average_mz = np.average(data[\"mz\"], weights=data[\"intensity\"])\n",
    "        peak_information.append({\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"max_intensity\": max_intensity,\n",
    "            \"average_mz\": average_mz,\n",
    "            \"width\": width\n",
    "        })\n",
    "    peak_informations.append(pd.DataFrame(peak_information))\n",
    "  \n",
    "peak_informations[0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle 'double peaks'\n",
    "\n",
    "* Converts 'double peaks' to separate peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Gaussian curve to peaks\n",
    "\n",
    "* Fit Gaussian curve to peaks and get fitted means.\n",
    "* Set the wanted resolution to ```default_resolution``` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_resolution = 280000\n",
    "\n",
    "# x: data; a: height; x0: position; c: sigma or width\n",
    "gauss  = lambda x, a, mu, sigma: a*np.exp(-(x-mu)**2/(2*sigma**2))\n",
    "\n",
    "def fit_gaussian(peak, resolution=default_resolution, show=False):\n",
    "    '''\n",
    "    returns: a: 'height'; mu: 'position'; sigma: 'width'\n",
    "    '''\n",
    "    mu = np.average(peak[\"mz\"], weights=peak[\"intensity\"])\n",
    "    sigma = mu/(resolution*2*np.sqrt(2*np.log(2)))\n",
    "    errfunc  = lambda p, x, y: (y - gauss(x, p[0], p[1], sigma))\n",
    "    init  = [peak[\"intensity\"].max(), mu]\n",
    "    out = leastsq(errfunc, init, args=(peak[\"mz\"], peak[\"intensity\"]))\n",
    "    c = out[0]\n",
    "    if show:\n",
    "        x = np.linspace(peak[\"mz\"].min(), peak[\"mz\"].max(), 1000)\n",
    "        fig, ax = plt.subplots(figsize=(8,6))\n",
    "        ax.ticklabel_format(useOffset=False)\n",
    "        plt.plot(peak[\"mz\"], peak[\"intensity\"], \"b\")\n",
    "        plt.plot(x, gauss(x, c[0], c[1], sigma), \"g\")\n",
    "        plt.plot((c[1],c[1]), (0.0,c[0]), \"g\", linestyle=\"--\")\n",
    "    return c[0], c[1], sigma\n",
    "\n",
    "# Test Fitting\n",
    "n_spectrum = 0\n",
    "n_peak = 9\n",
    "\n",
    "spectrum = spectrums[n_spectrum]\n",
    "peak_information = peak_informations[n_spectrum]\n",
    "peak = peak_information.iloc[n_peak]\n",
    "data = spectrum.iloc[int(peak[\"start\"]):int(peak[\"end\"] + 1)]\n",
    "a, mu, sigma = fit_gaussian(data, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'observed' column\n",
    "for spectrum, peak_information in zip(spectrums, peak_informations):\n",
    "    fitted_means = []\n",
    "    for i, peak in peak_information.iterrows():\n",
    "        data = spectrum.iloc[int(peak[\"start\"]):int(peak[\"end\"] + 1)]\n",
    "        a, mu, sigma = fit_gaussian(data)\n",
    "        fitted_means.append(mu)\n",
    "    peak_information[\"observed_mz\"] = fitted_means\n",
    "    \n",
    "peak_informations[0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify ions\n",
    "\n",
    "* Associate every ion from the ```peak_list``` to closest detected peak if there is detected peaks closer than ```theta```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def identify_peaks(peak_information, peak_list, theta = 0.01):\n",
    "    peak_information[\"formula\"] = None # For strings\n",
    "    peak_information[\"formula_mz\"] = np.nan # For floats\n",
    "    for key in peak_list.keys():\n",
    "        formula = key\n",
    "        true_mz = peak_list[key]\n",
    "        closest = peak_information[np.abs(peak_information[\"observed_mz\"] - true_mz) < theta]\n",
    "        if len(closest) > 0:\n",
    "            closest = closest.iloc[(closest['observed_mz'] - true_mz).abs().argsort()[:1]]\n",
    "            #print(\"True: {}; Observed: {}; Index: {}\".format(true_mz, closest[\"observed\"].values[0], closest.index.values[0]))\n",
    "            peak_information.at[closest.index.values[0], \"formula\"] = formula\n",
    "            peak_information.at[closest.index.values[0], \"formula_mz\"] = true_mz\n",
    "\n",
    "# Identify peaks\n",
    "for peak_information in peak_informations:\n",
    "    identify_peaks(peak_information, peak_list)\n",
    "\n",
    "# Lookup\n",
    "peak_informations[0].loc[peak_informations[0][\"formula\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty of mass\n",
    "\n",
    "* Analyse uncertainty of mass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculateMassUncertainty function takes a dataframe containing a processed spectrum with the following columns: formula, mz, observerd.\n",
    "It returns a dictionary with the uncertainty for each element calculated as the average of all the uncertainties for wich the element was present.\n",
    "By default it will take perform a weighted averged based on the number of elements in the compounds/ions.\n",
    "If weighted is set to False, it will only average the uncertainty based solely on the presence of the element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "def calculateMassUncertainty(peak_information, weighted=True, dfOutput=True, show=False):\n",
    "    data = [peak_information[\"formula\"], peak_information[\"formula_mz\"] - peak_information[\"observed_mz\"]]\n",
    "    headers = [\"formula\", \"uncertainty\"]\n",
    "    instance = pd.concat(data, axis=1, keys=headers)\n",
    "    elements = {}\n",
    "    for index, row in instance.iterrows():\n",
    "        ion = row[\"formula\"]\n",
    "        if not ion:\n",
    "            continue;\n",
    "        ion = ion if ion[-1] != '-' else ion[:-1]\n",
    "        tmp = mass.Composition(formula=ion)\n",
    "        v = row[\"uncertainty\"]\n",
    "        total = sum(tmp.values())\n",
    "        for e in tmp.keys():\n",
    "            f = 1\n",
    "            if weighted:\n",
    "                f = tmp[e] / total\n",
    "            if e not in elements:\n",
    "                elements[e] = [v*f]\n",
    "            else:\n",
    "                elements[e].append(v*f)\n",
    "    for e in elements.keys():\n",
    "        elements[e] = sum(elements[e]) / len(elements[e])\n",
    "    if show:\n",
    "        keys = elements.keys()\n",
    "        values = elements.values()\n",
    "        plt.figure(1)\n",
    "        plt.bar(keys, values)\n",
    "    if dfOutput:\n",
    "        df = pd.DataFrame(elements.items(), columns=['Element', 'Uncertainty'])\n",
    "        return df\n",
    "    else:\n",
    "        return elements\n",
    "    \n",
    "tmp = pd.concat(peak_informations, keys=range(len(spectrum_data_files)), names=[\"spectrum\"])\n",
    "calculateMassUncertainty(tmp, True, True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
