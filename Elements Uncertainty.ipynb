{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ongoing-latino",
   "metadata": {},
   "source": [
    "# Calculate Mass Uncertainty Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.signal as ss\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Example_Inputs/UncertaintyDf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-ready",
   "metadata": {},
   "source": [
    "The calculateMassUncertainty function takes a dataframe containing a processed spectrum with the following columns: formula, mz, observerd.  \n",
    "It returns a dictionary with the uncertainty for each element calculated as the average of all the uncertainties for wich the element was present.  \n",
    "By default it will take perform a weighted averged based on the number of elements in the compounds/ions.  \n",
    "If weighted is set to False, it will only average the uncertainty based solely on the presence of the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyteomics import mass\n",
    "\n",
    "def calculateMassUncertainty(processedSpectrum, weighted=True, dfOutput=True, show=False):\n",
    "    data = [processedSpectrum[\"formula\"],processedSpectrum[\"mz\"]-processedSpectrum[\"observed\"]]\n",
    "    headers = [\"formula\", \"uncertainty\"]\n",
    "    instance = pd.concat(data, axis=1, keys=headers)\n",
    "    elements = {}\n",
    "    for index, row in instance.iterrows():\n",
    "        ion = row[\"formula\"]\n",
    "        ion = ion if ion[-1] != '-' else ion[:-1]\n",
    "        tmp = mass.Composition(formula=ion)\n",
    "        v = row[\"uncertainty\"]\n",
    "        total = sum(tmp.values())\n",
    "        for e in tmp.keys():\n",
    "            f = 1\n",
    "            if weighted:\n",
    "                f = tmp[e] / total\n",
    "            if e not in elements:\n",
    "                elements[e] = [v*f]\n",
    "            else:\n",
    "                elements[e].append(v*f)\n",
    "    for e in elements.keys():\n",
    "        elements[e] = sum(elements[e]) / len(elements[e])\n",
    "    if show:\n",
    "        keys = elements.keys()\n",
    "        values = elements.values()\n",
    "        plt.figure(1)\n",
    "        plt.bar(keys, values)\n",
    "    if dfOutput:\n",
    "        df = pd.DataFrame(elements.items(), columns=['Element', 'Uncertainty'])\n",
    "        return df\n",
    "    else:\n",
    "        return elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#calculateMassUncertainty(df)\n",
    "calculateMassUncertainty(df, False, True,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-swift",
   "metadata": {},
   "source": [
    "# Experiments with the function above\n",
    "Here I try to graph the uncertainty for each element from all the spectra in the first small deviation file.  \n",
    "If you want to try, just change the folder variable below.\n",
    "\n",
    "**Important** Since this function requires processed spectra I am using Koli's code for that part. It is implemented with copy paste at the end, so run those cells before running mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = spectrum_data_directory = \"C:/Users/Antonio/Google Drive/Orbitrap project/Data/First Large Deviation file/2 mins\"\n",
    "peak_list_file = \"C:/Users/Antonio/Desktop/Esercizi prog/Data science project/peak list/peaklist_1e5_background.csv\"\n",
    "\n",
    "spectrum_data_files = []\n",
    "spectrum_data = []\n",
    "\n",
    "# Get data files\n",
    "for file in [f for f in listdir(folder) if isfile(join(folder, f))]:\n",
    "    path_to_file = join(folder, file)\n",
    "    #print(path_to_file)\n",
    "    if file.endswith(\".csv\"):\n",
    "        spectrum_data_files.append(path_to_file)\n",
    "for file in spectrum_data_files:\n",
    "    spectrum_data.append(readFile(file))\n",
    "\n",
    "peak_list = pd.read_csv(peak_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_spectra = []\n",
    "uncertaintydf = pd.DataFrame({'Element' : [], 'Uncertainty' : []})\n",
    "dfs = []\n",
    "for i in range(len(spectrum_data)):\n",
    "    identified_spectra.append(identifyPeaks(spectrum_data[i], peak_list, 0.002))\n",
    "    dfs.append(calculateMassUncertainty(identified_spectra[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertaintydf = pd.DataFrame({'Element' : [], 'Uncertainty' : []})\n",
    "for i in range(1, len(dfs)):\n",
    "    uncertaintydf = uncertaintydf.append(dfs[i], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = uncertaintydf[\"Element\"]\n",
    "values = uncertaintydf[\"Uncertainty\"]\n",
    "plt.figure(2)\n",
    "sns.set()\n",
    "plt.xlabel(\"Elements\")\n",
    "plt.ylabel(\"Uncertainty\")\n",
    "plt.title(\"Uncertainty by element\")\n",
    "plt.scatter(names, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-engineering",
   "metadata": {},
   "source": [
    "## Koli's code for identifying peaks\n",
    "Imported Koli's code for identifying peaks. Run this before the cell above.  \n",
    "I tried using \n",
    "```python\n",
    "from ipynb.fs.full.<notebook_name> import <function_name>\n",
    "```\n",
    "but I wasn't able to make it work so I just copy pasted the cells.  \n",
    "[An alternative](https://stackoverflow.com/questions/54317381/selectively-import-from-another-jupyter-notebook) that I didn't look much into was to import specific cells, but as I said, I didn't tried it very much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def readFile(fileName):\n",
    "    return pd.read_csv(fileName).iloc[1:,:2].to_numpy().astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def findPeakIndices(data):\n",
    "    n = int(round(sum(data[:,1] == 0)/2))\n",
    "    indices = np.zeros([n+1,2], dtype=\"uint32\")\n",
    "    a = False\n",
    "    ii = 0\n",
    "    for i in range(len(data[:,1])-1):\n",
    "        if data[i,1] == 0 and a:\n",
    "            indices[ii, 1] = i - 1\n",
    "            if ii != n:\n",
    "                indices[ii+1, 0] = i\n",
    "            ii += 1\n",
    "        a = data[i,1] == 0\n",
    "    last = n-sum(indices[:,0]>=indices[:,1])\n",
    "    indices = indices[0:last+1,:]\n",
    "    indices[last, 1] = len(data[:,0]) - 1\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import leastsq\n",
    "import numpy as np\n",
    "\n",
    "def getMean(peak):\n",
    "    mu = np.average(peak[:,0], weights=peak[:,1])\n",
    "    sigma = mu/(280000*2*np.sqrt(2*np.log(2)))\n",
    "    fitfunc  = lambda p, x: p[0]*np.exp(-0.5*((x-p[1])/sigma)**2)\n",
    "    errfunc  = lambda p, x, y: (y - fitfunc(p, x))\n",
    "    init  = [1.0, mu]\n",
    "    out = leastsq(errfunc, init, args=(peak[:,0], peak[:,1]))\n",
    "    c = out[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Calculate mean square error for the model\n",
    "def MSE(x, y, a, mu, sigma):\n",
    "    norm = lambda a, mu, x: a*np.exp(-0.5*((x-mu)/sigma)**2)\n",
    "    error = 0\n",
    "    for i in range(len(y)):\n",
    "        error = error + (y[i] - np.sum(norm(a,mu,x[i])))**2\n",
    "    return error/len(y)\n",
    "\n",
    "\n",
    "def errorFunction(x, y, sigma):\n",
    "    return lambda params: MSE(x, y, params[::2], params[1::2], sigma)\n",
    "\n",
    "# Function used to group values that are too close (abs(mu[n]-mu[n+1])<th) to each other together\n",
    "def group(mu, th):\n",
    "    groups = []\n",
    "    unassigned = np.linspace(0,len(mu)-1,len(mu)).astype(int)\n",
    "    while len(unassigned) > 0:\n",
    "        dist = abs(np.array(mu[unassigned]) - mu[unassigned[0]])\n",
    "        group = unassigned[dist < th]\n",
    "        unassigned = unassigned[dist >= th]\n",
    "        groups += [group]\n",
    "    return groups\n",
    "\n",
    "# Get one or more means depending on if there are multiple peaks in the data\n",
    "# by fitting one or more Gaussian distributions to the data using resolution of 280000 \n",
    "def getMeans(peaks):\n",
    "    ind = find_peaks(peaks[:,1], max(peaks[:,1])/20, prominence=max(peaks[:,1])/10)[0]\n",
    "    mu = peaks[ind,0]\n",
    "    n = len(mu)\n",
    "    sigma = mu/(280000*2*np.sqrt(2*np.log(2)))\n",
    "\n",
    "    init  = []\n",
    "    for i in range(len(mu)):\n",
    "        init += [np.mean(peaks[:,1]), mu[i]]\n",
    "    \n",
    "    # Fit n Gaussian distributions to the data\n",
    "    if n>1:\n",
    "        f = errorFunction(peaks[:,0], peaks[:,1], sigma)\n",
    "        params = minimize(f, init, method='BFGS').x\n",
    "    else:\n",
    "        params = getMean(peaks)\n",
    "    \n",
    "    a = params[::2]\n",
    "    mu = params[1::2]\n",
    "    \n",
    "    # Group fitted distributions that are too close to each other together\n",
    "    # and combine them\n",
    "    groups = group(mu, 1e-5)\n",
    "    a2 = np.zeros(len(groups))\n",
    "    mu2 = np.zeros(len(groups))\n",
    "    sigma2 = np.zeros(len(groups))\n",
    "    for i in range(len(groups)):\n",
    "        mu2[i] = np.mean(mu[groups[i]])\n",
    "        a2[i] = np.sum(a[groups[i]])\n",
    "        sigma2[i] = np.mean(sigma[groups[i]])\n",
    "    return mu2, a2, sigma2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get all peak means for the data\n",
    "def getAllMeans(peaks):\n",
    "    indices = findPeakIndices(peaks)\n",
    "    n = len(indices[:,0])\n",
    "    means = []\n",
    "    aa = []\n",
    "    sigmas = []\n",
    "    peaki = []\n",
    "    for i in range(n):\n",
    "        peak = peaks[indices[i,0]:indices[i,1]+1,:]\n",
    "        mu, a, sigma = getMeans(peak)\n",
    "        for ii in range(len(a)):\n",
    "            means += [mu[ii]]\n",
    "            aa += [a[ii]]\n",
    "            sigmas += [sigma[ii]]\n",
    "            peaki += [i]\n",
    "    return means, aa, sigmas, peaki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Identify peaks and return a data frame of peaks and their properties\n",
    "def identifyPeaks(data, peaklist, th):\n",
    "    peaklist['observed'] = np.zeros(len(peaklist['mz']))\n",
    "    peaklist['a'] = np.zeros(len(peaklist['mz']))\n",
    "    peaklist['sigma'] = np.zeros(len(peaklist['mz']))\n",
    "    peaklist['peak'] = np.zeros(len(peaklist['mz']))\n",
    "    peakMeans, a, sigmas, ind = getAllMeans(data)\n",
    "    trueValue = peaklist['mz'].to_numpy()\n",
    "    for i in range(len(trueValue)):\n",
    "        if min(abs(peakMeans - trueValue[i])) < th:\n",
    "            j = np.argmin(abs(peakMeans - trueValue[i]))\n",
    "            peaklist.iloc[i,2] = peakMeans[j]\n",
    "            peaklist.iloc[i,3] = a[j]\n",
    "            peaklist.iloc[i,4] = sigmas[j]\n",
    "            peaklist.iloc[i,5] = ind[j]\n",
    "    unidentified = np.linspace(0, len(trueValue)-1, len(trueValue))\n",
    "    unidentified = unidentified[peaklist['observed'].to_numpy() == 0]\n",
    "    return peaklist.drop(unidentified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectBestPeaks(data, n=10, test_n=0, randomTestSamples=True, threshold=0, forceThreshold=False, debug=False):\n",
    "    if n <=0:\n",
    "        return None\n",
    "    result = data\n",
    "    result[\"uncertainty\"] =  abs(data[\"formula_mz\"] - data[\"observed_mz\"])\n",
    "    result = result.sort_values(by=['uncertainty'], ascending=True) #specified ascending parameter for flexibility\n",
    "    diff = result\n",
    "    test_n = abs(test_n)\n",
    "    \n",
    "    if debug:    \n",
    "        print(result)\n",
    "    \n",
    "    if threshold:\n",
    "        threshold = abs(threshold)\n",
    "        filtered = result[result['uncertainty']<=threshold]\n",
    "    \n",
    "    if len(result) > n:\n",
    "        if threshold:\n",
    "            if len(filtered) > n:\n",
    "                result = filtered[0:n]\n",
    "            else:\n",
    "                if forceThreshold:\n",
    "                    result = filtered\n",
    "                else:\n",
    "                    result = result[0:n]\n",
    "        else:\n",
    "            result = result[0:n]\n",
    "    else:\n",
    "        if forceThreshold and threshold:\n",
    "            result = filtered\n",
    "        else:\n",
    "            x = max(len(result), n)\n",
    "            result = result[0:x]\n",
    "            \n",
    "    diff = pd.concat([result,diff]).drop_duplicates(keep=False)\n",
    "    if test_n != 0:\n",
    "        test_n = min(test_n, len(diff))\n",
    "        if randomTestSamples:\n",
    "            diff = diff.sample(test_n)\n",
    "        else:\n",
    "            diff = diff[0:test_n]\n",
    "    return result, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Example_Inputs/UncertaintyDf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = selectBestPeaks(df, 5, 10, True, 1.397722e-06, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-trunk",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-essay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
